apiVersion: grizzly.grafana.com/v1alpha1
kind: PrometheusRuleGroup
metadata:
    name: tempo_alerts
    namespace: integration-tempo
spec:
    rules:
        - alerts: []
          annotations:
            message: |
                {{ $labels.job }} {{ $labels.route }} is experiencing {{ printf "%.2f" $value }}s 99th percentile latency.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoRequestLatency
          labels:
            severity: critical
          name: TempoRequestLatency
          query: cluster_namespace_job_route:tempo_request_duration_seconds:99quantile{route!~"metrics|/frontend.Frontend/Process|debug_pprof"} > 3
          type: alerting
        - alerts: []
          annotations:
            message: There are {{ printf "%f" $value }} unhealthy compactor(s).
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoCompactorUnhealthy
          duration: 900
          labels:
            severity: critical
          name: TempoCompactorUnhealthy
          query: max by (cluster, namespace) (tempo_ring_members{name="compactor",namespace=~".*",state="Unhealthy"}) > 0
          type: alerting
        - alerts: []
          annotations:
            message: There are {{ printf "%f" $value }} unhealthy distributor(s).
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoDistributorUnhealthy
          duration: 900
          labels:
            severity: warning
          name: TempoDistributorUnhealthy
          query: max by (cluster, namespace) (tempo_ring_members{name="distributor",namespace=~".*",state="Unhealthy"}) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 2 compactions have failed in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoCompactionsFailing
          duration: 3600
          labels:
            severity: critical
          name: TempoCompactionsFailing
          query: sum by (cluster, namespace) (increase(tempodb_compaction_errors_total[1h])) > 2 and sum by (cluster, namespace) (increase(tempodb_compaction_errors_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 2 flush retries have occurred in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoIngesterFlushesFailing
          duration: 300
          labels:
            severity: warning
          name: TempoIngesterFlushesUnhealthy
          query: sum by (cluster, namespace) (increase(tempo_ingester_failed_flushes_total[1h])) > 2 and sum by (cluster, namespace) (increase(tempo_ingester_failed_flushes_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 2 flush retries have failed in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoIngesterFlushesFailing
          duration: 300
          labels:
            severity: critical
          name: TempoIngesterFlushesFailing
          query: sum by (cluster, namespace) (increase(tempo_ingester_flush_failed_retries_total[1h])) > 2 and sum by (cluster, namespace) (increase(tempo_ingester_flush_failed_retries_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 2 polls have failed in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoPollsFailing
          duration: 0
          labels:
            severity: critical
          name: TempoPollsFailing
          query: sum by (cluster, namespace) (increase(tempodb_blocklist_poll_errors_total[1h])) > 2 and sum by (cluster, namespace) (increase(tempodb_blocklist_poll_errors_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 2 tenant index failures in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoTenantIndexFailures
          duration: 0
          labels:
            severity: critical
          name: TempoTenantIndexFailures
          query: sum by (cluster, namespace) (increase(tempodb_blocklist_tenant_index_errors_total[1h])) > 2 and sum by (cluster, namespace) (increase(tempodb_blocklist_tenant_index_errors_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: No tenant index builders for tenant {{ $labels.tenant }}. Tenant index will quickly become stale.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoNoTenantIndexBuilders
          duration: 300
          labels:
            severity: critical
          name: TempoNoTenantIndexBuilders
          query: sum by (cluster, namespace, tenant) (tempodb_blocklist_tenant_index_builder) == 0 and max by (cluster, namespace) (tempodb_blocklist_length) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Tenant index age is 600 seconds old for tenant {{ $labels.tenant }}.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoTenantIndexTooOld
          duration: 300
          labels:
            severity: critical
          name: TempoTenantIndexTooOld
          query: max by (cluster, namespace, tenant) (tempodb_blocklist_tenant_index_age_seconds) > 600
          type: alerting
        - alerts: []
          annotations:
            message: Tempo block list length is up 40 percent over the last 7 days.  Consider scaling compactors.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoBlockListRisingQuickly
          duration: 900
          labels:
            severity: critical
          name: TempoBlockListRisingQuickly
          query: avg(tempodb_blocklist_length{namespace=".*"}) / avg(tempodb_blocklist_length{job=~"$namespace/$component",namespace=".*"} offset 1w) > 1.4
          type: alerting
        - alerts: []
          annotations:
            message: '{{ $labels.job }} failed to reload overrides.'
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoBadOverrides
          duration: 900
          labels:
            severity: warning
          name: TempoBadOverrides
          query: sum by (cluster, namespace, job) (tempo_runtime_config_last_reload_successful{namespace=~".*"} == 0)
          type: alerting
        - alerts: []
          annotations:
            message: Greater than 5 user-configurable overrides reloads failed in the past hour.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoTenantIndexFailures
          duration: 0
          labels:
            severity: critical
          name: TempoUserConfigurableOverridesReloadFailing
          query: sum by (cluster, namespace) (increase(tempo_overrides_user_configurable_overrides_reload_failed_total[1h])) > 5 and sum by (cluster, namespace) (increase(tempo_overrides_user_configurable_overrides_reload_failed_total[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Ingesters in {{ $labels.cluster }}/{{ $labels.namespace }} are receiving more data/second than desired, add more ingesters.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoProvisioningTooManyWrites
          duration: 900
          labels:
            severity: warning
          name: TempoProvisioningTooManyWrites
          query: avg by (cluster, namespace) (rate(tempo_ingester_bytes_received_total{job=~".+/ingester"}[5m])) / 1024 / 1024 > 30
          type: alerting
        - alerts: []
          annotations:
            message: There are too many outstanding compaction blocks in {{ $labels.cluster }}/{{ $labels.namespace }} for tenant {{ $labels.tenant }}, increase compactor's CPU or add more compactors.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoCompactorsTooManyOutstandingBlocks
          duration: 21600
          labels:
            severity: warning
          name: TempoCompactorsTooManyOutstandingBlocks
          query: sum by (cluster, namespace, tenant) (tempodb_compaction_outstanding_blocks{container="compactor",namespace=~".*"}) / ignoring (tenant) group_left () count by (cluster, namespace) (tempo_build_info{container="compactor",namespace=~".*"}) > 100
          type: alerting
        - alerts: []
          annotations:
            message: There are too many outstanding compaction blocks in {{ $labels.cluster }}/{{ $labels.namespace }} for tenant {{ $labels.tenant }}, increase compactor's CPU or add more compactors.
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoCompactorsTooManyOutstandingBlocks
          duration: 86400
          labels:
            severity: critical
          name: TempoCompactorsTooManyOutstandingBlocks
          query: sum by (cluster, namespace, tenant) (tempodb_compaction_outstanding_blocks{container="compactor",namespace=~".*"}) / ignoring (tenant) group_left () count by (cluster, namespace) (tempo_build_info{container="compactor",namespace=~".*"}) > 250
          type: alerting
        - alerts: []
          annotations:
            message: Tempo ingester has encountered errors while replaying a block on startup in {{ $labels.cluster }}/{{ $labels.namespace }} for tenant {{ $labels.tenant }}
            runbook_url: https://github.com/grafana/tempo/tree/main/operations/tempo-mixin/runbook.md#TempoIngesterReplayErrors
          duration: 300
          labels:
            severity: critical
          name: TempoIngesterReplayErrors
          query: sum by (cluster, namespace, tenant) (increase(tempo_ingester_replay_errors_total{namespace=~".*"}[5m])) > 0
          type: alerting
        - alerts: []
          annotations:
            message: Tempo ingester has not received any trace data in the last 5 minutes. Check upstream services or ingestion pipeline.
            runbook_url: ""
          duration: 300
          labels:
            severity: critical
          name: TempoIngesterNotReceivedTraceData
          query: rate(tempo_ingester_bytes_received_total[5m]) < 1
          type: alerting
